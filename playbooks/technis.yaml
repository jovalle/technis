- import_playbook: reset.yaml
  when:
    - reset is defined
    - reset | bool

- import_playbook: common.yaml
  tags:
    - common

- import_playbook: gpu.yaml
  tags:
    - gpu

- import_playbook: cri.yaml
  tags:
    - cri

- import_playbook: k3s.yaml
  tags:
    - k3s

- name: deploy gpu plugin
  hosts: control_plane
  run_once: yes
  tasks:
    - name: add gpu label
      command: kubectl label node nexus kubernetes.io/gpu=nvidia --overwrite
    - name: deploy nvidia-device-plugin
      shell: |
        cat <<EOF | kubectl apply -f -
        apiVersion: apps/v1
        kind: DaemonSet
        metadata:
          name: nvidia-device-plugin
          namespace: kube-system
        spec:
          selector:
            matchLabels:
              k8s-app: nvidia-device-plugin
          template:
            metadata:
              labels:
                k8s-app: nvidia-device-plugin
            spec:
              priorityClassName: system-node-critical
              nodeSelector:
                kubernetes.io/gpu: nvidia
              tolerations:
              - key: CriticalAddonsOnly
                operator: Exists
              containers:
              - env:
                - name: DP_DISABLE_HEALTHCHECKS
                  value: xids
                image: nvidia/k8s-device-plugin:v0.10.0
                name: nvidia-device-plugin-ctr
                securityContext:
                  allowPrivilegeEscalation: true
                  capabilities:
                    drop: ["ALL"]
                volumeMounts:
                  - name: device-plugin
                    mountPath: /var/lib/kubelet/device-plugins
              volumes:
                - name: device-plugin
                  hostPath:
                    path: /var/lib/kubelet/device-plugins
        EOF

    - name: wait for ndp daemonset to become ready
      command: kubectl -n kube-system rollout status daemonset nvidia-device-plugin --timeout 60s
      register: ndp_rollout_status
      retries: 10

    - name: deploy job
      shell: |
        cat <<EOF | kubectl apply -f -
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: cuda-vector-add
        spec:
          template:
            spec:
              restartPolicy: OnFailure
              containers:
                - name: cuda-vector-add
                  image: "k8s.gcr.io/cuda-vector-add:v0.1"
                  resources:
                    limits:
                      nvidia.com/gpu: 1
        EOF

    - name: wait for job completion
      command: kubectl wait --for=condition=complete job cuda-vector-add --timeout 120s
  tags:
    - gpu

- import_playbook: cert-manager.yaml
  tags:
    - cert-manager
    - services

- import_playbook: metallb.yaml
  tags:
    - cert-manager
    - services